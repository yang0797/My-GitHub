{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e286973-a1e8-4f59-81e4-d1b0c7bcdbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Softmax 및 Cross-Entropy 테스트 시작 ---\n",
      "\n",
      "[A] 단일 샘플 - 임의의 로짓 값 (N=10개):\n",
      "[-2.26826365 -1.31458828 -0.94452616  0.36868699 -3.54080815 -1.07896917\n",
      "  0.50863966 -2.74328722  0.57502042  0.71216002]\n",
      "\n",
      "[B] Softmax 적용 후 예측 확률:\n",
      "[0.0127474  0.03308244 0.04789757 0.17808803 0.00357078 0.04187219\n",
      " 0.2048403  0.00792723 0.21889922 0.25107483]\n",
      "  -> 확률 총합: 1.000000\n",
      "\n",
      "[C] 임의의 실제 레이블 (원-핫 인코딩, 정답 인덱스: 5):\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "[D] Cross-Entropy Loss (단일 샘플): 3.1731\n",
      "\n",
      "\n",
      "[E] 배치 샘플 - 임의의 로짓 값 (배치 크기=3, N=10개):\n",
      "[[ 0.95792839 -1.31409677 -0.04024454  1.80978701 -2.41117589  3.12260054\n",
      "  -0.88754015 -0.51732438 -1.32175446  3.03246013]\n",
      " [-0.29307763 -1.03498871 -0.45127952 -1.89080292 -2.610542    0.33407947\n",
      "   1.66096753 -0.76285332 -2.07362181  2.79620595]\n",
      " [-2.26587027 -5.67007325  1.81360715  1.57158608  2.33259709 -1.21994164\n",
      "   0.65464761 -0.79344399  0.12301685  0.48866863]]\n",
      "\n",
      "[F] Softmax 적용 후 배치 예측 확률:\n",
      "[[4.75926967e-02 4.90695781e-03 1.75403929e-02 1.11557253e-01\n",
      "  1.63816225e-03 4.14615451e-01 7.51732814e-03 1.08854447e-02\n",
      "  4.86952536e-03 3.78876789e-01]\n",
      " [2.91415667e-02 1.38773009e-02 2.48774972e-02 5.89697948e-03\n",
      "  2.87111710e-03 5.45611810e-02 2.05657203e-01 1.82176311e-02\n",
      "  4.91170623e-03 6.39987818e-01]\n",
      " [3.87208305e-03 1.28682086e-04 2.28896523e-01 1.79692843e-01\n",
      "  3.84621594e-01 1.10201040e-02 7.18305943e-02 1.68815091e-02\n",
      "  4.22109527e-02 6.08451138e-02]]\n",
      "  -> 각 샘플별 확률 총합:\n",
      "     1.000000\n",
      "     1.000000\n",
      "     1.000000\n",
      "\n",
      "[G] 임의의 실제 레이블 (배치, 원-핫 인코딩):\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "[H] Cross-Entropy Loss (배치 평균): 3.5519\n",
      "\n",
      "--- Softmax 및 Cross-Entropy 테스트 종료 ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred, epsilon=1e-10):\n",
    "    y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    loss = -np.sum(y_true * np.log(y_pred), axis=-1)\n",
    "    return np.mean(loss)\n",
    "\n",
    "# 임의의 값을 입력하여 Softmax 및 Cross-Entropy 계산\n",
    "print(\"--- Softmax 및 Cross-Entropy 테스트 시작 ---\")\n",
    "\n",
    "N_CLASSES = 10 # 5개의 서로 다른 레이블\n",
    "\n",
    "# 임의의 로짓 값 생성-\n",
    "random_logits_single_sample = np.random.randn(N_CLASSES) * 2 # N_CLASSES 개만큼 임의의 숫자 생성, 스케일 조절\n",
    "print(f\"\\n[A] 단일 샘플 - 임의의 로짓 값 (N={N_CLASSES}개):\")\n",
    "print(random_logits_single_sample)\n",
    "\n",
    "# Softmax 함수\n",
    "predicted_probabilities_single_sample = softmax(random_logits_single_sample)\n",
    "print(f\"\\n[B] Softmax 적용 후 예측 확률:\")\n",
    "print(predicted_probabilities_single_sample)\n",
    "print(f\"  -> 확률 총합: {np.sum(predicted_probabilities_single_sample):.6f}\")\n",
    "\n",
    "# 임의의 실제 레이블 생성\n",
    "random_true_label_index = np.random.randint(0, N_CLASSES) # 0부터 N_CLASSES-1 중 임의의 인덱스 선택\n",
    "true_label_one_hot_single_sample = np.zeros(N_CLASSES)\n",
    "true_label_one_hot_single_sample[random_true_label_index] = 1\n",
    "\n",
    "print(f\"\\n[C] 임의의 실제 레이블 (원-핫 인코딩, 정답 인덱스: {random_true_label_index}):\")\n",
    "print(true_label_one_hot_single_sample)\n",
    "\n",
    "# Cross-Entropy Loss 계산\n",
    "# 예측 확률과 실제 레이블을 비교하여 손실 값을 계산.\n",
    "loss_single_sample = cross_entropy_loss(true_label_one_hot_single_sample,\n",
    "                                        predicted_probabilities_single_sample)\n",
    "print(f\"\\n[D] Cross-Entropy Loss (단일 샘플): {loss_single_sample:.4f}\")\n",
    "\n",
    "BATCH_SIZE = 3 # 3개의 샘플 \n",
    "\n",
    "# 임의의 로짓 값 생성\n",
    "# (BATCH_SIZE, N_CLASSES) 2차원 배열 생성\n",
    "random_logits_batch = np.random.randn(BATCH_SIZE, N_CLASSES) * 2\n",
    "print(f\"\\n\\n[E] 배치 샘플 - 임의의 로짓 값 (배치 크기={BATCH_SIZE}, N={N_CLASSES}개):\")\n",
    "print(random_logits_batch)\n",
    "\n",
    "# Softmax 함수\n",
    "predicted_probabilities_batch = softmax(random_logits_batch)\n",
    "print(f\"\\n[F] Softmax 적용 후 배치 예측 확률:\")\n",
    "print(predicted_probabilities_batch)\n",
    "\n",
    "print(f\"  -> 각 샘플별 확률 총합:\")\n",
    "for s in np.sum(predicted_probabilities_batch, axis=-1):\n",
    "    print(f\"     {s:.6f}\")\n",
    "\n",
    "# 임의의 실제 레이블 생성\n",
    "true_label_one_hot_batch = np.zeros((BATCH_SIZE, N_CLASSES))\n",
    "for i in range(BATCH_SIZE):\n",
    "    random_true_label_index_batch = np.random.randint(0, N_CLASSES)\n",
    "    true_label_one_hot_batch[i, random_true_label_index_batch] = 1\n",
    "\n",
    "print(f\"\\n[G] 임의의 실제 레이블 (배치, 원-핫 인코딩):\")\n",
    "print(true_label_one_hot_batch)\n",
    "\n",
    "# Cross-Entropy Loss 계산\n",
    "# 배치 전체에 대한 평균 손실 값을 반환\n",
    "loss_batch = cross_entropy_loss(true_label_one_hot_batch,\n",
    "                                predicted_probabilities_batch)\n",
    "print(f\"\\n[H] Cross-Entropy Loss (배치 평균): {loss_batch:.4f}\")\n",
    "\n",
    "print(\"\\n--- Softmax 및 Cross-Entropy 테스트 종료 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e9a40-8565-4a01-a816-77a0d39f01a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
